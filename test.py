# %%
import pandas as pd
train=pd.read_csv("/home/corp/xingqiao.lin/code/GeoStab/data/ddG/S8754.csv", sep=',')
train

# %%
import sys
import os
if not os.path.exists('/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train'):
    os.mkdir('/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train')
import pandas as pd
train=pd.read_csv("/home/corp/xingqiao.lin/code/GeoStab/data/ddG/S8754.csv", sep=',')

names=train['name'].tolist()
for name in names:
    name=name.replace(' ', '_')
    if not os.path.exists(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}'):
        os.mkdir(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}')
    if not os.path.exists(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/wt_data'):
        os.mkdir(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/wt_data')
    if not os.path.exists(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/mut_data'):
        os.mkdir(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/mut_data')
        


# %%
for name in names:
        # è·å–å¯¹åº”çš„è¡Œæ•°æ®
        row = train[train['name'] == name].iloc[0]
        wt_seq = row['wt_seq']
        mut_seq = row['mut_seq']
        
        # åˆ›å»ºWT FASTAæ–‡ä»¶
        wt_fasta_path = f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/wt_data/result.fasta'
        with open(wt_fasta_path, 'w') as f:
            f.write(f">result\n")
            f.write(f"{wt_seq}\n")
        
        # åˆ›å»ºMUT FASTAæ–‡ä»¶
        mut_fasta_path = f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/mut_data/result.fasta'
        with open(mut_fasta_path, 'w') as f:
            f.write(f">{name}_MUT\n")
            f.write(f"{mut_seq}\n")
        
        print(f"âœ… åˆ›å»º {name} çš„FASTAæ–‡ä»¶")
        

# %%
import subprocess
from tqdm import tqdm

for name in tqdm(names, desc="ç”Ÿæˆç‰¹å¾"):
    clean_name = name.replace(' ', '_')
    wt_fasta_path = f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{clean_name}/wt_data'
    
    # ç”Ÿæˆfixed_embedding
    if not os.path.exists(f'{wt_fasta_path}/fixed_embedding.pt'):
        cmd = f"python /home/corp/xingqiao.lin/code/GeoStab/generate_features/fixed_embedding.py --fasta_file {wt_fasta_path}/result.fasta --saved_folder {wt_fasta_path}"
        subprocess.run(cmd, shell=True)
    
    print(f"âœ… {name} ç‰¹å¾ç”Ÿæˆå®Œæˆ")




# %%
import os, torch
from Bio import SeqIO
from transformers import AutoTokenizer, EsmForMaskedLM
from tqdm import tqdm
import re
import shutil

HF_MODEL_DIR = "/home/corp/xingqiao.lin/.cache/huggingface/hub/facebook/esm1v_t33_650M_UR90S_1"

# ä½¿ç”¨PyTorchæ ¼å¼åŠ è½½æ¨¡å‹ï¼ˆä¸ä½¿ç”¨safetensorsï¼‰
tok = AutoTokenizer.from_pretrained(HF_MODEL_DIR, use_fast=False, local_files_only=True)
model = EsmForMaskedLM.from_pretrained(
    HF_MODEL_DIR, 
    local_files_only=True,
    use_safetensors=False  # æ˜ç¡®æŒ‡å®šä¸ä½¿ç”¨safetensors
).eval().to("cpu")

def extract_pdb_id(clean_name):
    """ä»clean_nameä¸­æå–PDB ID"""
    # åŒ¹é… rcsb_1ABC_A_... æ ¼å¼
    match = re.match(r'rcsb_([A-Z0-9]+)_', clean_name)
    if match:
        return match.group(1)
    return None

def find_same_pdb_variants(pdb_id, all_names):
    """æ‰¾åˆ°æ‰€æœ‰ç›¸åŒPDB IDçš„å˜ä½“"""
    variants = []
    for name in all_names:
        clean_name = name.replace(' ', '_')
        if clean_name.startswith(f'rcsb_{pdb_id}_'):
            variants.append(clean_name)
    return variants

# ç»Ÿè®¡ä¿¡æ¯
processed_pdb_ids = set()
skipped_count = 0
copied_count = 0
generated_count = 0

for name in tqdm(names, desc="ç”Ÿæˆç‰¹å¾"):
    clean_name = name.replace(' ', '_')
    wt_fasta_path = f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{clean_name}/wt_data'
    seq_path = f'{wt_fasta_path}/result.fasta'
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(seq_path):
        print(f"âš ï¸ è·³è¿‡ {name}: FASTAæ–‡ä»¶ä¸å­˜åœ¨")
        continue
    
    # æå–PDB ID
    pdb_id = extract_pdb_id(clean_name)
    if not pdb_id:
        print(f"âš ï¸ è·³è¿‡ {name}: æ— æ³•æå–PDB ID")
        continue
    
    out_path = os.path.join(wt_fasta_path, "esm1v-1.pt")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»ç”Ÿæˆ
    if os.path.exists(out_path):
        print(f"â­ï¸ {name}: esm1v-1.pt å·²å­˜åœ¨ï¼Œè·³è¿‡")
        continue
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™ä¸ªPDB ID
    if pdb_id in processed_pdb_ids:
        print(f"â­ï¸ {name}: PDB ID {pdb_id} å·²å¤„ç†è¿‡ï¼Œè·³è¿‡")
        continue
    
    try:
        # ç”Ÿæˆç‰¹å¾
        seq = str(next(SeqIO.parse(seq_path, "fasta")).seq)
        inputs = tok(seq, return_tensors="pt", add_special_tokens=True)
        with torch.no_grad():
            out = model(**inputs, output_hidden_states=True)
            reps = out.hidden_states[-1][0, 1:-1, :].cpu().clone()
        
        # ä¿å­˜åˆ°å½“å‰ç›®å½•
        torch.save(reps, out_path)
        print(f"âœ… ç”Ÿæˆ {name}: {out_path}, shape={tuple(reps.shape)}")
        generated_count += 1
        
        # æ ‡è®°è¿™ä¸ªPDB IDå·²å¤„ç†
        processed_pdb_ids.add(pdb_id)
        
        # æ‰¾åˆ°æ‰€æœ‰ç›¸åŒPDB IDçš„å˜ä½“
        same_pdb_variants = find_same_pdb_variants(pdb_id, names)
        
        # å¤åˆ¶åˆ°æ‰€æœ‰ç›¸åŒPDB IDçš„ç›®å½•
        for variant in same_pdb_variants:
            if variant == clean_name:
                continue  # è·³è¿‡è‡ªå·±
            
            variant_wt_path = f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{variant}/wt_data'
            variant_out_path = os.path.join(variant_wt_path, "esm1v-1.pt")
            
            # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(variant_wt_path):
                print(f"âš ï¸ è·³è¿‡ {variant}: ç›®æ ‡ç›®å½•ä¸å­˜åœ¨")
                continue
            
            # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(variant_out_path):
                print(f"â­ï¸ {variant}: esm1v-1.pt å·²å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶")
                continue
            
            try:
                # å¤åˆ¶ç‰¹å¾æ–‡ä»¶
                shutil.copy2(out_path, variant_out_path)
                print(f"ğŸ“‹ å¤åˆ¶ {pdb_id} ç‰¹å¾åˆ° {variant}")
                copied_count += 1
            except Exception as e:
                print(f"âŒ å¤åˆ¶åˆ° {variant} å¤±è´¥: {e}")
        
        print(f"ğŸ¯ PDB {pdb_id}: ç”Ÿæˆäº†1ä¸ªï¼Œå¤åˆ¶äº†{len(same_pdb_variants)-1}ä¸ªå˜ä½“")
        
    except Exception as e:
        print(f"âŒ {name}: å¤„ç†å¤±è´¥ - {e}")

# è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
print(f"\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
print(f"âœ… ç”Ÿæˆç‰¹å¾: {generated_count}")
print(f"ğŸ“‹ å¤åˆ¶ç‰¹å¾: {copied_count}")
print(f"â­ï¸ è·³è¿‡: {skipped_count}")
print(f"ğŸ¯ å¤„ç†çš„PDB IDæ•°: {len(processed_pdb_ids)}")


#ç”ŸæˆESM-1V-1ç‰¹å¾
import sys
import os
if not os.path.exists('/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train'):
    os.mkdir('/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train')
import pandas as pd
train=pd.read_csv("/home/corp/xingqiao.lin/code/GeoStab/data/ddG/S8754.csv", sep=',')

names=train['name'].tolist()
for name in names:
    name=name.replace(' ', '_')
    if not os.path.exists(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}'):
        os.mkdir(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}')
    if not os.path.exists(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/wt_data'):
        os.mkdir(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/wt_data')
    if not os.path.exists(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/mut_data'):
        os.mkdir(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/mut_data')
import subprocess
for name in names:  # åªå¤„ç†å‰5ä¸ª
    clean_name = name.replace(' ', '_')
    wt_fasta_path = f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{clean_name}/wt_data'
    
    # ç”Ÿæˆfixed_embedding
    if not os.path.exists(f'{wt_fasta_path}/esm1v-1.pt'):
        cmd = f"python /home/corp/xingqiao.lin/code/GeoStab/generate_features/esm1v_logits.py --model_index 1 --fasta_file {wt_fasta_path}/result.fasta --saved_folder {wt_fasta_path}"
        subprocess.run(cmd, shell=True)
    
    print(f"âœ… {name} ç‰¹å¾ç”Ÿæˆå®Œæˆ")

# %%
#!/usr/bin/env bash

# ğŸš€ PDBä¸‹è½½è„šæœ¬ - Pythonç‰ˆæœ¬
import os
import re
import requests
from tqdm import tqdm
import time

def find_pdb_ids(data_dir):
    """ä»ç›®å½•ç»“æ„ä¸­æå–PDB ID"""
    pdb_ids = set()
    
    # æŸ¥æ‰¾æ‰€æœ‰rcsb_*ç›®å½•
    for root, dirs, files in os.walk(data_dir):
        for dir_name in dirs:
            if dir_name.startswith('rcsb_'):
                # æå–PDB ID (rcsb_1ABC_A_... -> 1ABC)
                match = re.match(r'rcsb_([A-Z0-9]+)_', dir_name)
                if match:
                    pdb_id = match.group(1)
                    pdb_ids.add(pdb_id)
    
    return sorted(list(pdb_ids))
#ä¸‹è½½PDBæ–‡ä»¶
def download_pdb(pdb_id, output_dir, timeout=30):
    """ä¸‹è½½å•ä¸ªPDBæ–‡ä»¶"""
    pdb_id_lower = pdb_id.lower()
    url = f"https://files.rcsb.org/download/{pdb_id_lower}.pdb"
    output_file = os.path.join(output_dir, f"{pdb_id}.pdb")
    
    try:
        response = requests.get(url, timeout=timeout)
        response.raise_for_status()
        
        with open(output_file, 'w') as f:
            f.write(response.text)
        
        return True, f"âœ… {pdb_id} ä¸‹è½½æˆåŠŸ"
    
    except requests.exceptions.RequestException as e:
        return False, f"âŒ {pdb_id} ä¸‹è½½å¤±è´¥: {e}"
    except Exception as e:
        return False, f"âŒ {pdb_id} ä¸‹è½½å‡ºé”™: {e}"

# é…ç½®
data_dir = "/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train"
output_dir = "/home/corp/xingqiao.lin/code/GeoStab/pdbs"

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(output_dir, exist_ok=True)

print("ğŸ” æ­£åœ¨æ‰«æç›®å½•ç»“æ„...")
pdb_ids = find_pdb_ids(data_dir)

print(f"ğŸ“Š æ‰¾åˆ° {len(pdb_ids)} ä¸ªå”¯ä¸€çš„PDB ID")
print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
print("=" * 60)

# ç»Ÿè®¡å˜é‡
success_count = 0
failed_count = 0
skipped_count = 0

# ä¸‹è½½PDBæ–‡ä»¶
for pdb_id in tqdm(pdb_ids, desc="ä¸‹è½½PDBæ–‡ä»¶"):
    output_file = os.path.join(output_dir, f"{pdb_id}.pdb")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(output_file):
        skipped_count += 1
        tqdm.write(f"â­ï¸  {pdb_id} å·²å­˜åœ¨ï¼Œè·³è¿‡")
        continue
    
    # ä¸‹è½½æ–‡ä»¶
    success, message = download_pdb(pdb_id, output_dir)
    
    if success:
        success_count += 1
        tqdm.write(message)
    else:
        failed_count += 1
        tqdm.write(message)
    
    # æ·»åŠ å°å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
    time.sleep(0.1)

# è¾“å‡ºç»Ÿè®¡ç»“æœ
print("\n" + "=" * 60)
print("ğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡:")
print("=" * 60)
print(f"âœ… æˆåŠŸä¸‹è½½: {success_count}")
print(f"â­ï¸  è·³è¿‡ (å·²å­˜åœ¨): {skipped_count}")
print(f"âŒ ä¸‹è½½å¤±è´¥: {failed_count}")
print(f"ğŸ“Š æ€»è®¡å¤„ç†: {len(pdb_ids)}")

# æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶
downloaded_files = [f for f in os.listdir(output_dir) if f.endswith('.pdb')]
print(f"ğŸ“ è¾“å‡ºç›®å½•ä¸­çš„PDBæ–‡ä»¶æ•°: {len(downloaded_files)}")

if failed_count > 0:
    print("\nâš ï¸  éƒ¨åˆ†æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–PDB IDæ˜¯å¦æœ‰æ•ˆ")

print("\nğŸ‰ PDBä¸‹è½½ä»»åŠ¡å®Œæˆï¼")


# %%
import os
import re
import shutil
from tqdm import tqdm
from collections import defaultdict

def find_pdb_directories(data_dir):
    """æ‰¾åˆ°æ‰€æœ‰rcsbç›®å½•å¹¶æå–PDB ID"""
    pdb_to_dirs = defaultdict(list)
    
    # æŸ¥æ‰¾æ‰€æœ‰rcsb_*ç›®å½•
    for root, dirs, files in os.walk(data_dir):
        for dir_name in dirs:
            if dir_name.startswith('rcsb_'):
                # æå–PDB ID (rcsb_1ABC_A_... -> 1ABC)
                match = re.match(r'rcsb_([A-Z0-9]+)_', dir_name)
                if match:
                    pdb_id = match.group(1)
                    full_path = os.path.join(root, dir_name, 'wt_data')
                    if os.path.exists(full_path):
                        pdb_to_dirs[pdb_id].append(full_path)
    
    return pdb_to_dirs

def distribute_pdb_files(pdb_to_dirs, source_dir):
    """å°†PDBæ–‡ä»¶åˆ†å‘åˆ°æ‰€æœ‰ç›¸å…³ç›®å½•"""
    success_count = 0
    error_count = 0
    skipped_count = 0
    
    print(f"ğŸ” å¼€å§‹åˆ†å‘PDBæ–‡ä»¶...")
    print(f"ğŸ“ æºç›®å½•: {source_dir}")
    print("=" * 80)
    
    for pdb_id, target_dirs in tqdm(pdb_to_dirs.items(), desc="åˆ†å‘PDBæ–‡ä»¶"):
        source_file = os.path.join(source_dir, f"{pdb_id}.pdb")
        
        # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(source_file):
            tqdm.write(f"âŒ {pdb_id}.pdb æºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            error_count += 1
            continue
        
        # å¤åˆ¶åˆ°æ‰€æœ‰ç›¸å…³ç›®å½•
        for target_dir in target_dirs:
            target_file = os.path.join(target_dir, f"{pdb_id}.pdb")
            
            try:
                # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                if os.path.exists(target_file):
                    skipped_count += 1
                    tqdm.write(f"â­ï¸  {pdb_id}.pdb å·²å­˜åœ¨äº {target_dir}")
                    continue
                
                # å¤åˆ¶æ–‡ä»¶
                shutil.copy2(source_file, target_file)
                success_count += 1
                tqdm.write(f"âœ… {pdb_id}.pdb -> {target_dir}")
                
            except Exception as e:
                error_count += 1
                tqdm.write(f"âŒ å¤åˆ¶ {pdb_id}.pdb åˆ° {target_dir} å¤±è´¥: {e}")
    
    return success_count, error_count, skipped_count

def main():
    # é…ç½®
    data_dir = "/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train"
    source_dir = "/home/corp/xingqiao.lin/code/GeoStab/pdbs"  # PDBæ–‡ä»¶æºç›®å½•
    
    print("ğŸš€ å¯åŠ¨PDBæ–‡ä»¶åˆ†å‘è„šæœ¬...")
    print("=" * 80)
    
    # æ£€æŸ¥æºç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(source_dir):
        print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
        print("è¯·å…ˆè¿è¡ŒPDBä¸‹è½½è„šæœ¬")
        return
    
    # æ‰¾åˆ°æ‰€æœ‰PDBç›®å½•æ˜ å°„
    print("ğŸ” æ­£åœ¨æ‰«æç›®å½•ç»“æ„...")
    pdb_to_dirs = find_pdb_directories(data_dir)
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(pdb_to_dirs)} ä¸ªå”¯ä¸€çš„PDB ID")
    print(f"ğŸ“ æºç›®å½•: {source_dir}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_dirs = sum(len(dirs) for dirs in pdb_to_dirs.values())
    print(f"ğŸ“Š æ€»å…±éœ€è¦åˆ†å‘åˆ° {total_dirs} ä¸ªç›®å½•")
    print("=" * 80)
    
    # åˆ†å‘æ–‡ä»¶
    success_count, error_count, skipped_count = distribute_pdb_files(pdb_to_dirs, source_dir)
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š åˆ†å‘å®Œæˆç»Ÿè®¡:")
    print("=" * 80)
    print(f"âœ… æˆåŠŸå¤åˆ¶: {success_count}")
    print(f"â­ï¸  è·³è¿‡ (å·²å­˜åœ¨): {skipped_count}")
    print(f"âŒ å¤åˆ¶å¤±è´¥: {error_count}")
    print(f"ğŸ“Š æ€»è®¡å¤„ç†: {success_count + skipped_count + error_count}")
    
    # æ£€æŸ¥æ¯ä¸ªPDB IDçš„åˆ†å‘æƒ…å†µ
    print("\nğŸ“‹ å„PDBæ–‡ä»¶åˆ†å‘è¯¦æƒ…:")
    print("-" * 50)
    for pdb_id, dirs in pdb_to_dirs.items():
        source_file = os.path.join(source_dir, f"{pdb_id}.pdb")
        if os.path.exists(source_file):
            print(f"âœ… {pdb_id}: åˆ†å‘åˆ° {len(dirs)} ä¸ªç›®å½•")
        else:
            print(f"âŒ {pdb_id}: æºæ–‡ä»¶ä¸å­˜åœ¨")
    
    print("\nğŸ‰ PDBæ–‡ä»¶åˆ†å‘å®Œæˆï¼")

# è¿è¡Œä¸»å‡½æ•°
main()

ESM-1V 1-5 ç‰¹å¾ç”Ÿæˆ
import os, torch
from Bio import SeqIO
from transformers import AutoTokenizer, EsmForMaskedLM

# ===== é…ç½® =====
BASE_DIR = "/home/corp/xingqiao.lin/.cache/huggingface/hub/facebook"
MODEL_PREFIX = "esm1v_t33_650M_UR90S_"  # _1 â€¦ _5
FASTA = "/path/to/protein.fasta"
SAVE  = "/path/to/save"
DEVICE = "cpu"   # æˆ– "cuda"
os.makedirs(SAVE, exist_ok=True)

# è¯»ç¬¬ä¸€æ¡åºåˆ—
seq = str(next(SeqIO.parse(FASTA, "fasta")).seq)

# tokenizer å„æ¨¡å‹ç›¸åŒï¼Œåªéœ€åŠ è½½ä¸€æ¬¡
tok_dir = os.path.join(BASE_DIR, f"{MODEL_PREFIX}1")
tokenizer = AutoTokenizer.from_pretrained(tok_dir, use_fast=False, local_files_only=True)

# åˆ†è¯ï¼ˆè‡ªåŠ¨åŠ  <cls> ä¸ </s>ï¼‰
inputs = tokenizer(seq, return_tensors="pt", add_special_tokens=True)
inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

for i in range(1, 6):
    model_dir = os.path.join(BASE_DIR, f"{MODEL_PREFIX}{i}")
    print(f"Loading model {i} from: {model_dir}")

    model = EsmForMaskedLM.from_pretrained(model_dir, local_files_only=True).eval().to(DEVICE)

    with torch.no_grad():
        out  = model(**inputs, output_hidden_states=True)
        last = out.hidden_states[-1]          # [1, L+2, 1280]
        reps = last[0, 1:-1, :].detach()      # å»æ‰ <cls>, </s> â†’ [L, 1280]
        reps_cpu = reps.to("cpu").clone()

    out_path = os.path.join(SAVE, f"esm1v-{i}.pt")
    torch.save(reps_cpu, out_path)
    print(f"âœ… saved: {out_path}  shape={tuple(reps_cpu.shape)}")


# %%
import sys
import os
if not os.path.exists('/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train'):
    os.mkdir('/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train')
import pandas as pd
train=pd.read_csv("/home/corp/xingqiao.lin/code/GeoStab/data/ddG/S8754.csv", sep=',')

names=train['name'].tolist()
for name in names:
    name=name.replace(' ', '_')
    if not os.path.exists(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}'):
        os.mkdir(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}')
    if not os.path.exists(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/wt_data'):
        os.mkdir(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/wt_data')
    if not os.path.exists(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/mut_data'):
        os.mkdir(f'/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train/{name}/mut_data')

# %%
import os
import glob
import shutil
from tqdm import tqdm

def rename_all_pdb_to_relaxed(base_dir):
    """å°†ddG_trainç›®å½•ä¸‹æ‰€æœ‰å­ç›®å½•ä¸­çš„PDBæ–‡ä»¶é‡å‘½åä¸ºrelaxed.pdb"""
    
    print(f"ğŸ” å¼€å§‹æ‰«æç›®å½•: {base_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«wt_dataçš„ç›®å½•
    wt_data_dirs = []
    for root, dirs, files in os.walk(base_dir):
        if "wt_data" in root:
            wt_data_dirs.append(root)
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(wt_data_dirs)} ä¸ªwt_dataç›®å½•")
    
    success_count = 0
    skip_count = 0
    error_count = 0
    
    for wt_dir in tqdm(wt_data_dirs, desc="é‡å‘½åPDBæ–‡ä»¶"):
        try:
            # æŸ¥æ‰¾ç›®å½•ä¸‹çš„PDBæ–‡ä»¶
            pdb_files = glob.glob(os.path.join(wt_dir, "*.pdb"))
            
            if not pdb_files:
                print(f"âš ï¸ {wt_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°PDBæ–‡ä»¶")
                skip_count += 1
                continue
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰relaxed.pdb
            relaxed_pdb = os.path.join(wt_dir, "relaxed.pdb")
            if os.path.exists(relaxed_pdb):
                print(f"â­ï¸ {os.path.basename(wt_dir)}: å·²ç»æœ‰relaxed.pdbï¼Œè·³è¿‡")
                skip_count += 1
                continue
            
            # å¦‚æœåªæœ‰ä¸€ä¸ªPDBæ–‡ä»¶ï¼Œç›´æ¥é‡å‘½å
            if len(pdb_files) == 1:
                old_pdb = pdb_files[0]
                shutil.move(old_pdb, relaxed_pdb)
                print(f"âœ… {os.path.basename(wt_dir)}: {os.path.basename(old_pdb)} -> relaxed.pdb")
                success_count += 1
            
            # å¦‚æœæœ‰å¤šä¸ªPDBæ–‡ä»¶ï¼Œé€‰æ‹©æœ€å¤§çš„é‚£ä¸ª
            elif len(pdb_files) > 1:
                # æŒ‰æ–‡ä»¶å¤§å°æ’åºï¼Œé€‰æ‹©æœ€å¤§çš„
                pdb_files.sort(key=lambda x: os.path.getsize(x), reverse=True)
                old_pdb = pdb_files[0]
                shutil.move(old_pdb, relaxed_pdb)
                print(f"âœ… {os.path.basename(wt_dir)}: {os.path.basename(old_pdb)} -> relaxed.pdb (é€‰æ‹©æœ€å¤§æ–‡ä»¶)")
                success_count += 1
                
                # åˆ é™¤å…¶ä»–PDBæ–‡ä»¶
                for other_pdb in pdb_files[1:]:
                    os.remove(other_pdb)
                    print(f"ğŸ—‘ï¸ åˆ é™¤: {os.path.basename(other_pdb)}")
            
        except Exception as e:
            error_count += 1
            print(f"âŒ {os.path.basename(wt_dir)}: å¤„ç†å‡ºé”™ - {e}")
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š é‡å‘½åå®Œæˆç»Ÿè®¡:")
    print("=" * 80)
    print(f"âœ… æˆåŠŸé‡å‘½å: {success_count}")
    print(f"â­ï¸ è·³è¿‡: {skip_count}")
    print(f"âŒ å¤„ç†å¤±è´¥: {error_count}")
    print(f"ğŸ“Š æ€»è®¡å¤„ç†: {len(wt_data_dirs)}")
    
    print("\nğŸ‰ PDBæ–‡ä»¶é‡å‘½åå®Œæˆï¼")

# è¿è¡Œè„šæœ¬
base_dir = "/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train"
rename_all_pdb_to_relaxed(base_dir)

# %%
import os
import sys
import subprocess
from tqdm import tqdm
import time

# é…ç½®è·¯å¾„
GEOSTAB_DIR = "/home/corp/xingqiao.lin/code/GeoStab"
DATA_DIR = "/home/corp/xingqiao.lin/code/GeoStab/data/ddG_train"
CSV_FILE = "/home/corp/xingqiao.lin/code/GeoStab/data/ddG/S8754.csv"

def check_file_exists(file_path, min_size=1):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°å¤§äºmin_sizeå­—èŠ‚"""
    return os.path.exists(file_path) and os.path.getsize(file_path) > min_size

def run_command(cmd, description=""):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""
    try:
        print(f"ğŸ”„ {description}")
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(f"âœ… {description} å®Œæˆ")
            return True
        else:
            print(f"âŒ {description} å¤±è´¥: {result.stderr}")
            return False
    except subprocess.TimeoutExpired:
        print(f"â° {description} è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ {description} å‡ºé”™: {e}")
        return False

def load_names_from_csv(csv_file):
    """ä»CSVæ–‡ä»¶åŠ è½½è›‹ç™½è´¨åç§°"""
    names = []
    try:
        with open(csv_file, 'r') as f:
            lines = f.readlines()
        
        # è·³è¿‡æ ‡é¢˜è¡Œï¼Œæå–ç¬¬ä¸€åˆ—ï¼ˆnameåˆ—ï¼‰
        for line in lines[1:]:
            if line.strip():
                name = line.split(',')[0].strip()
                names.append(name)
        
        return names
    except Exception as e:
        print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
        return []

def process_wt_features(name, clean_name):
    """å¤„ç†å•ä¸ªè›‹ç™½è´¨çš„WTç‰¹å¾"""
    wt_folder = f'{DATA_DIR}/{clean_name}/wt_data'
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    fasta_file = f'{wt_folder}/result.fasta'
    pdb_file = f'{wt_folder}/relaxed.pdb'
    
    if not check_file_exists(fasta_file):
        print(f"âš ï¸ è·³è¿‡ {name}: FASTAæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    if not check_file_exists(pdb_file):
        print(f"âš ï¸ è·³è¿‡ {name}: PDBæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    success = True
    
    # 1. ç”Ÿæˆcoordinate.pt
    coord_file = f'{wt_folder}/coordinate.pt'
    if not check_file_exists(coord_file):
        cmd = f"python {GEOSTAB_DIR}/generate_features/coordinate.py --pdb_file {pdb_file} --saved_folder {wt_folder}"
        if not run_command(cmd, f"ç”Ÿæˆ {name} çš„coordinate.pt"):
            success = False
    else:
        print(f"â­ï¸ {name} coordinate.pt å·²å­˜åœ¨ï¼Œè·³è¿‡")
    
    # 2. ç”Ÿæˆpairç‰¹å¾ - ä¿®æ­£å‚æ•°å
    pair_file = f'{wt_folder}/pair.pt'
    if not check_file_exists(pair_file):
        # æ£€æŸ¥coordinate.ptæ˜¯å¦å­˜åœ¨ï¼Œå› ä¸ºpair.pyéœ€è¦å®ƒ
        if check_file_exists(coord_file):
            cmd = f"python {GEOSTAB_DIR}/generate_features/pair.py --coordinate_file {coord_file} --saved_folder {wt_folder}"
            if not run_command(cmd, f"ç”Ÿæˆ {name} çš„pairç‰¹å¾"):
                success = False
        else:
            print(f"âš ï¸ {name}: coordinate.ptä¸å­˜åœ¨ï¼Œæ— æ³•ç”Ÿæˆpairç‰¹å¾")
            success = False
    else:
        print(f"â­ï¸ {name} pair.pt å·²å­˜åœ¨ï¼Œè·³è¿‡")
    
    return success

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨GeoStab WTç‰¹å¾ç”Ÿæˆè„šæœ¬...")
    print("ğŸ“Š åªç”Ÿæˆcoordinate.ptå’Œpairç‰¹å¾")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½æ•°æ®...")
    names = load_names_from_csv(CSV_FILE)
    print(f"âœ… åŠ è½½äº† {len(names)} ä¸ªè›‹ç™½è´¨")
    
    # ç»Ÿè®¡å˜é‡
    success_count = 0
    skip_count = 0
    error_count = 0
    
    print("\nğŸ” å¼€å§‹å¤„ç†WTç‰¹å¾...")
    print("=" * 80)
    
    # å¤„ç†æ¯ä¸ªè›‹ç™½è´¨
    for name in tqdm(names, desc="ç”ŸæˆWTç‰¹å¾"):
        clean_name = name.replace(' ', '_')
        
        try:
            if process_wt_features(name, clean_name):
                success_count += 1
                print(f"âœ… {name} WTç‰¹å¾ç”Ÿæˆå®Œæˆ")
            else:
                skip_count += 1
                print(f"â­ï¸ {name} è·³è¿‡")
        except Exception as e:
            error_count += 1
            print(f"âŒ {name} å¤„ç†å‡ºé”™: {e}")
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
    print("=" * 80)
    print(f"âœ… æˆåŠŸå¤„ç†: {success_count}")
    print(f"â­ï¸ è·³è¿‡: {skip_count}")
    print(f"âŒ å¤„ç†å¤±è´¥: {error_count}")
    print(f"ğŸ“Š æ€»è®¡: {len(names)}")
    
    # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
    print("\nğŸ” æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶...")
    coord_count = 0
    pair_count = 0
    
    for name in names:
        clean_name = name.replace(' ', '_')
        wt_folder = f'{DATA_DIR}/{clean_name}/wt_data'
        
        if check_file_exists(f'{wt_folder}/coordinate.pt'):
            coord_count += 1
        if check_file_exists(f'{wt_folder}/pair.pt'):
            pair_count += 1
    
    print(f"ğŸ“Š coordinate.pt æ–‡ä»¶æ•°: {coord_count}")
    print(f"ğŸ“Š pair.pt æ–‡ä»¶æ•°: {pair_count}")
    
    print("\nğŸ‰ WTç‰¹å¾ç”Ÿæˆå®Œæˆï¼")

if __name__ == "__main__":
    main()
